---
title: "rightTruncation"
author: "Andrew Edwards"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rightTruncation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 4,
  fig.height = 4,
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(rightTruncation)
```

# Likelihood fitting of Weibull delay distribution to right-truncated data

This vignette should be self-contained (without going into all the calculations) such
that the functions can be applied to other data.See the readme at
<https://github.com/andrew-edwards/rightTruncation> for
details, including the link to the manuscript that contains the mathematical
background. In particular, Appendix A.2 gives full details and derivations.

The data in British Columbia, Canada, are counts $h_{nr}$ of
the number of individuals whose case was reported (test was positive) at the end
of day $r$ and whose symptoms are estimated to have started on day $n$.

## Simple matrix example

An example simulated data set gives the values of $h_{nr}$ as a matrix:
```{r simulated}
h_nr_simulated <- h_nr_simulate(N = 10)
h_nr_simulated
```
The matrix is upper diagonal (all the entries below the diagonal are
zero) because $h_{nr} = 0$ for $r < n$, since a case cannot be reported before
the start of symptoms.
Day $N$ is the final day of the data ($N = 10$ in the example), such that the
non-zero values are
$\{ h_{nr} \}_{n = 0, 1, 2, ..., N; n \leq r \leq N}$.

The counts are right-truncated on day $N$ -- there are individuals
whose symptoms started on day $n$ who will be reported in the future (after
$N$), but we do not yet know when. For example, for people whose symptoms
started on day $n=8$, we only know about those whose cases were reported on days
8, 9 and 10. Anyone who will have a delay between symptom onset and reporting that
is longer than 2 days is not in our data set and, crucially, we don't even know about them yet.
The cases are considered to be reported at
the end of day $r$ because there are values of $h_{nn} > 0$. The example matrix
is size 11x11 since days start at 0 and end at $N=10$.

The maximum likelihood is calculated by minimising the negative log-likelihood function:
```{r likematrix}
MLE_res = nlm(f = negLL_Weibull_counts_matrix,
              p = c(3, 15),
              h_nr = h_nr_simulated)
```
(Note that such code usually gives warnings about NaNs being produced during the
optimisation; these have been suppressed in this vignette).
The main results of interest are the MLEs for $k$ and $\lambda$, and also the
resulting mean and median:
```{r res}
k_MLE <- MLE_res$estimate[1]
lambda_MLE <- MLE_res$estimate[2]
k_MLE      # shape
lambda_MLE # scale
mean_using_MLEs <- lambda_MLE * gamma(1 + 1/k_MLE)
mean_using_MLEs
median_using_MLEs <- lambda_MLE * (log(2))^(1/k_MLE)
median_using_MLEs
```

Wrapper function for simulating the same data set and fitting it, just showing
the fitted parameters here (the random number seed is fixed in the simulation
function, hence the result is the same as above):
```{r simest}
h_nr_one_sim_fit(N=10)$estimate
```

## Real data, analyse as a data frame

Once we have much larger values of $N$ it makes more sense to use a long data
frame format for the data, particularly since we know the matrix is always upper
triangular.

The actual data in British Columbia look like this (random noise has
been added here because the data are not public), with a simple histogram:
```{r, delaydata}
delay_data
time_report_vec = 0:(as.numeric(max(delay_data$time_to_report)) + 2)
hist(as.numeric(delay_data$time_to_report),
     breaks = time_report_vec,
     right = FALSE,
     xlab = "Time from symptom onset to reported case (days)",
     main = "",
     col = "lightgrey")
```

To see the individual cases as points, with barplots that summarise the values for each day.:
```{r, cases}
plotdelay1 <- plot_time_to_report(delay_data, x_axis = "onset",
                                  xLim = c(lubridate::ymd("2020-02-28"),
                                           max(delay_data$reported_date) + 2))
plotdelay2 <- plot_time_to_report(delay_data,
                                  xLim = c(lubridate::ymd("2020-02-28"),
                                           max(delay_data$reported_date) + 2))
```
```{r, plots, fig.width = 8, fig.asp = 0.8}
gridExtra::grid.arrange(
             plotdelay1,
             plotdelay2,
             ncol=1)
```

By definition there can be no values above the dashed 1:1 line in the top panel,
because the delays to reporting are too long (any cases will be reported in the
future, with data only up to `r max(delay_data$reported_date)`.

The actual values we need for the likelihood calculations are just counts
$h_{nr}$ of the number of cases that had symptom onset on day $n$ and were
reported on day $r$, where $n$ and $r$ take values from $0$ to $N$. This
function converts the above tibble into the required form:
```{r convert}
h_nr_tibble <- make_h_nr_tibble(delay_data)
h_nr_tibble
# Show how many of each h_nr values there are:
summary(as.factor(h_nr_tibble$h_nr))
```

To calculate the maximum likelihood estimates for $k$ and $\lambda$:
```{r MLEdata}
MLE <- nlm(f = negLL_Weibull_counts_df,
           p = c(3, 15),
           h_nr_df = h_nr_tibble)
```



Then do example in data frame format, which will be easier for translating real
data (above one is good for explaining the subject). Also plot some real or
modified real data.
