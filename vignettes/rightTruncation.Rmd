---
title: "rightTruncation"
author: "Andrew Edwards"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rightTruncation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 4,
  fig.height = 4,
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(rightTruncation)
```

# Likelihood fitting of Weibull delay distribution to right-truncated data

This vignette should be self-contained (without going into all the calculations) such
that the functions can be applied to other data.See the readme at
<https://github.com/andrew-edwards/rightTruncation> for
details, including the link to the manuscript that contains the mathematical
background. In particular, Appendix A.2 gives full details and derivations.

The data in British Columbia, Canada, are counts $h_{nr}$ of
the number of individuals whose case was reported (test was positive) at the end
of day $r$ and whose symptoms are estimated to have started on day $n$.

## Simple matrix example

An example simulated data set gives the values of $h_{nr}$ as a matrix:
```{r simulated}
h_nr_simulated <- h_nr_simulate(N = 10)
h_nr_simulated
```
The matrix is upper diagonal (all the entries below the diagonal are
zero) because $h_{nr} = 0$ for $r < n$, since a case cannot be reported before
the start of symptoms.
Day $N$ is the final day of the data ($N = 10$ in the example), such that the
non-zero values are
$\{ h_{nr} \}_{n = 0, 1, 2, ..., N; n \leq r \leq N}$.

The counts are right-truncated on day $N$ -- there are individuals
whose symptoms started on day $n$ who will be reported in the future (after
$N$), but we do not yet know when. For example, for people whose symptoms
started on day $n=8$, we only know about those whose cases were reported on days
8, 9 and 10. Anyone who will have a delay between symptom onset and reporting that
is longer than 2 days is not in our data set and, crucially, we don't even know about them yet.
The cases are considered to be reported at
the end of day $r$ because there are values of $h_{nn} > 0$. The example matrix
is size 11x11 since days start at 0 and end at $N=10$.

The maximum likelihood is calculated by minimising the negative log-likelihood function:
```{r likematrix}
MLE_res = nlm(f = negLL_Weibull_counts_matrix,
              p = c(3, 15),
              h_nr = h_nr_simulated)
```
(Note that such code usually gives warnings about NaNs being produced during the
optimisation; these have been suppressed in this vignette).
The main results of interest are the MLEs for $k$ and $\lambda$, and also the
resulting mean and median:
```{r res}
k_MLE <- MLE_res$estimate[1]
lambda_MLE <- MLE_res$estimate[2]
k_MLE      # shape
lambda_MLE # scale
mean_using_MLEs <- lambda_MLE * gamma(1 + 1/k_MLE)
mean_using_MLEs
median_using_MLEs <- lambda_MLE * (log(2))^(1/k_MLE)
median_using_MLEs
```

Wrapper function for simulating the same data set and fitting it, just showing
the fitted parameters here (the random number seed is fixed in the simulation
function, hence the result is the same as above):
```{r simest}
h_nr_one_sim_fit(N=10)$estimate
```

## Real data, analyse as a data frame

Once we have much larger values of $N$ it makes more sense to use a long data
frame format for the data, particularly since we know the matrix is always upper
triangular.

The actual data in British Columbia look like this, with a simple histogram of
the delay times between symptom onset and reporting of a case:
```{r, delaydata}
delay_data
time_report_vec = 0:(as.numeric(max(delay_data$time_to_report)) + 2)
hist(as.numeric(delay_data$time_to_report),
     breaks = time_report_vec,
     right = FALSE,
     xlab = "Time from symptom onset to reported case (days)",
     main = "",
     col = "lightgrey")
```

To see the individual cases as points, with barplots that summarise the values for each day.:
```{r, cases}
plotdelay1 <- plot_time_to_report(delay_data, x_axis = "onset",
                                  xLim = c(lubridate::ymd("2020-02-28"),
                                           max(delay_data$reported_date) + 2))
plotdelay2 <- plot_time_to_report(delay_data,
                                  xLim = c(lubridate::ymd("2020-02-28"),
                                           max(delay_data$reported_date) + 2))
```
```{r, plots, fig.width = 8, fig.asp = 0.8}
gridExtra::grid.arrange(
             plotdelay1,
             plotdelay2,
             ncol=1)
```

By definition there can be no values above the dashed 1:1 line in the top panel,
because the delays to reporting are too long (any cases will be reported in the
future, with data only up to `r max(delay_data$reported_date)`.

The actual values we need for the likelihood calculations are just counts
$h_{nr}$ of the number of cases that had symptom onset on day $n$ and were
reported on day $r$, where $n$ and $r$ take values from $0$ to $N$. This
function converts the above tibble into the required form:
```{r convert}
h_nr_tibble <- make_h_nr_tibble(delay_data)
h_nr_tibble
# Show how many of each h_nr values there are:
summary(as.factor(h_nr_tibble$h_nr))
```

To calculate the maximum likelihood estimates for $k$ and $\lambda$:
```{r MLEtibble}
MLE <- nlm(f = negLL_Weibull_counts_tibble,
           p = c(3,15),
           h_nr_tibble = h_nr_tibble)

k_MLE <- MLE$estimate[1]
lambda_MLE <- MLE$estimate[2]
k_MLE      # shape
lambda_MLE # scale
mean_using_MLEs <- lambda_MLE * gamma(1 + 1/k_MLE)
mean_using_MLEs
median_using_MLEs <- lambda_MLE * (log(2))^(1/k_MLE)
median_using_MLEs
```

For the manuscript, we used the data between February 29 and April 2:
```{r manuscript}
h_nr_manuscript <- make_h_nr_tibble(delay_data,
                                    day_0 = lubridate::ymd("2020-02-29"),
                                    day_N = lubridate::ymd("2020-04-02"))
MLE_man <- nlm(f = negLL_Weibull_counts_tibble,
               p = c(3,15),
               h_nr_tibble = h_nr_manuscript)
k_MLE_man <- MLE_man$estimate[1]
lambda_MLE_man <- MLE_man$estimate[2]
k_MLE_man      # shape
lambda_MLE_man # scale
mean_using_MLEs_man <- lambda_MLE_man * gamma(1 + 1/k_MLE_man)
mean_using_MLEs_man
median_using_MLEs_man <- lambda_MLE_man * (log(2))^(1/k_MLE_man)
median_using_MLEs_man
```

There are `r sum(h_nr_manuscript$h_nr)` individual cases there. In the
manuscript we reported only 535, the difference being due to TODO [presumably
updated data since the code was run for the manuscript]; difference is small
($k_{MLE} = 1.73$ and $\lambda_{MLE} = 9.85$ in the manuscript).

The following code is for plotting results for British Columbia and New Zealand,
but is commented out because the New Zealand data cannot be made public.
TODO: functionalise the plotting, and use BC as example.

```{r MLEhist, eval=FALSE}
png(filename = "delay-hist-BC-NZ.png",
    width = 6.8*240,
    height = 4.5*240,
    res = 240)
max_delay <- max(c(h_nr_manuscript$r - h_nr_manuscript$n, h_NZ$breaks) + 2)
time_report_vec = seq(0, max_delay, by=0.1)

h_NZ <- readRDS(paste0(here::here(), "/data-raw/NZ_histogram.rds"))

time_report_BC = dweibull(time_report_vec,
                          shape = k_MLE_man,
                          scale = lambda_MLE_man) * sum(h_nr_manuscript$h_nr)
time_report_NZ = dweibull(time_report_vec,
                          shape = 1.53289,
                          scale = 7.818021) * sum(h_NZ$counts)
par(mfrow=c(1,2))
hist(rep(h_nr_manuscript$r - h_nr_manuscript$n, h_nr_manuscript$h_nr),
     breaks = 0:max_delay,
     right = FALSE,
     xlab = "Days from symptom onset to reporting",
     main = "British Columbia",
     col = "lightgrey")
lines(time_report_vec,
      time_report_BC,
      col = "red",
      lwd = 2)
plot(h_NZ,
     xlab = "Days from symptom onset to reporting",
     main = "New Zealand",
     col = "lightgrey")
lines(time_report_vec,
      time_report_NZ,
      col = "red",
      lwd = 2)
dev.off()
```

### Confidence intervals

TODO:
Have added sizeSpectra to DESCRIPTION, now test with this code from SIR-explore
that I've only copied here:

Do univariate ones (Bolker book implies they're often
close to bivariate), set one parameter at MLE and
get interval for the other (was not running every time in .Rmd since takes a while,
so running once then putting results in):
```{r conf, eval=FALSE}
k_confint <- profLike(negLL.Weibull.counts.df,
                      MLE = k_MLE,
                      minNegLL = MLE.res$minimum,
                      vecInc = 0.001,
                      h_nr_df = h_nr_df,
                      lambda_MLE = lambda_MLE)
k_confint  #  1.603928 1.857928   = 1.60-1.86

lambda_confint <- profLike(negLL.Weibull.counts.df,
                      MLE = lambda_MLE,
                      minNegLL = MLE.res$minimum,
                      vecInc = 0.001,
                      vecDiff = 0.65,
                      h_nr_df = h_nr_df,
                      k_MLE = k_MLE)
lambda_confint  #  9.304579 10.462579   = 9.30-10.46
# THEN check nlm works okay still
```

# New Zealand data

[This summarises from above what is needed]

We would like to fit a Weibull distribution to data on the delays between a
person having the onset of symptoms and them being reported as a confirmed cases
of COVID-19 in New Zealand. The data we have in British Columbia is a tibble
with these (self-explanatory) headings (final column is just difference between
the first two):

```{r NZ1}
delay_data
```

This gets converted into the desired form for the likelihood function:

```{r NZ2}
h_nr_tibble <- make_h_nr_tibble(delay_data)
h_nr_tibble
```

and the maximum likelihood calculation is then run using:
```{r NZ3}
MLE <- nlm(f = negLL_Weibull_counts_tibble,
           p = c(3,15),
           h_nr_tibble = h_nr_tibble)
MLE
```

Please let me know what form the NZ data are in, and I can write a wrapper
function to enable you to run the likelihood calculation.
